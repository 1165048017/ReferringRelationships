{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization_utils import get_att_map, objdict, get_dict\n",
    "from scipy.stats import multivariate_normal\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create initial attention.\n",
    "im_width = 14\n",
    "im_height = 14\n",
    "\n",
    "def create_gaussian(center):\n",
    "    xlim = (-3, 3)\n",
    "    ylim = (-3, 3)\n",
    "    kernel = multivariate_normal(mean=center, cov=np.eye(2))\n",
    "    x = np.linspace(xlim[0], xlim[1], im_width)\n",
    "    y = np.linspace(ylim[0], ylim[1], im_height)\n",
    "    xx, yy = np.meshgrid(x,y)\n",
    "    xxyy = np.c_[xx.ravel(), yy.ravel()]\n",
    "    zz = kernel.pdf(xxyy)\n",
    "    in_att = zz.reshape((im_height, im_width))\n",
    "    return in_att\n",
    "\n",
    "in_att = create_gaussian((0, 0))\n",
    "plt.imshow(in_att)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "data_type = \"vrd\"\n",
    "###################\n",
    "if data_type==\"vrd\":\n",
    "    nrows=7\n",
    "    ncols=5\n",
    "    ssn_checkpoint = \"/data/ranjaykrishna/ReferringRelationships/temp/vrd_ssn_convs3/model29-1.33.h5\"\n",
    "    sym_ssn_checkpoint = \"/data/ranjaykrishna/ReferringRelationships/temp/vrd_sym_ssn_convs3/model29-1.29.h5\"\n",
    "    vocab_dir = os.path.join('data/VRD')\n",
    "elif data_type==\"clevr\":\n",
    "    nrows=3\n",
    "    ncols=2\n",
    "    ssn_checkpoint = \"/data/ranjaykrishna/ReferringRelationships/temp/clevr_ssn/model03-0.15.h5\"\n",
    "    sym_ssn_checkpoint = \"/data/ranjaykrishna/ReferringRelationships/temp/clevr_sym_ssn_convs3_iterations2/model00-0.18.h5\"\n",
    "    #annotations_test = json.load(open(\"/data/chami/ReferringRelationships/data/Clevr/annotations_test.json\"))\n",
    "    #img_dir = '/data/chami/ReferringRelationships/data/Clevr/images/val'\n",
    "    vocab_dir = os.path.join('/data/chami/ReferringRelationships/data/Clevr/')\n",
    "predicate_dict, obj_subj_dict = get_dict(vocab_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all the weights\n",
    "model_weights = h5py.File(sym_ssn_checkpoint)\n",
    "params = objdict(json.load(open(os.path.join(os.path.dirname(sym_ssn_checkpoint), \"args.json\"), \"r\")))\n",
    "conv_filters = {}\n",
    "inv_conv_filters = {}\n",
    "for i in range(params.num_predicates):\n",
    "    predicate = predicate_dict[i]\n",
    "    conv_filters[predicate] = []\n",
    "    inv_conv_filters[predicate] = []\n",
    "    for j in range(params.nb_conv_att_map):\n",
    "        if 'conv0-predicate0' in model_weights:\n",
    "            conv_weights_name = \"conv{}-predicate{}\".format(j, i)\n",
    "            inv_conv_weights_name = \"conv{}-inv-predicate{}\".format(j, i)\n",
    "        else:\n",
    "            conv_weights_name = \"conv{}-predicate{}-0\".format(j, i)\n",
    "            inv_conv_weights_name = \"conv{}-predicate{}-1\".format(j, i)\n",
    "        if j == 0:\n",
    "            conv_filters[predicate] += [model_weights[conv_weights_name][conv_weights_name]['kernel:0'][()]]\n",
    "            inv_conv_filters[predicate] += [model_weights[inv_conv_weights_name][inv_conv_weights_name]['kernel:0'][()]]\n",
    "        else:\n",
    "            conv_filters[predicate] += [model_weights[conv_weights_name][conv_weights_name]['kernel:0'][()]]\n",
    "            inv_conv_filters[predicate] += [model_weights[inv_conv_weights_name][inv_conv_weights_name]['kernel:0'][()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "predicate = \"inside\"\n",
    "###################\n",
    "sess = tf.InteractiveSession()\n",
    "att = in_att.reshape(1, im_height, im_width, 1)\n",
    "att = K.constant(att)\n",
    "for j in range(params.nb_conv_att_map):\n",
    "    kernel = np.array(conv_filters[predicate][j])\n",
    "    att = K.conv2d(att, kernel, padding='same', data_format='channels_last')\n",
    "    att = K.relu(att)\n",
    "att = K.sum(att, axis=3)\n",
    "att = att.eval().reshape((im_height, im_width))\n",
    "sess.close()\n",
    "plt.imshow(att, interpolation='gaussian')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
